{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cat and dog classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bs18b019/Data-science-work/blob/main/Cat_and_dog_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtRRWet_YELw"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "\n",
        "# define image property\n",
        "Image_Width=128\n",
        "Image_Height=128\n",
        "Image_Size=(Image_Width,Image_Height)\n",
        "Image_Channels=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOj0vnN5YV66",
        "outputId": "648014a4-2478-43b1-8565-f36538c45ce7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKHkScKnYuss"
      },
      "source": [
        "# Generating a data frame which will have file name and level\n",
        "folder = '/content/drive/MyDrive/data scienec work/dogs-vs-cats/train/train/'\n",
        "filenames=os.listdir(folder)\n",
        "\n",
        "\n",
        "categories=[]\n",
        "for f_name in filenames:\n",
        "    category=f_name.split('.')[0]\n",
        "    if category=='dog':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "\n",
        "\n",
        "\n",
        "df=pd.DataFrame({\n",
        "    'filename':filenames,\n",
        "    'category':categories\n",
        "})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhnhevZ5cEWV"
      },
      "source": [
        "Creating directory "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1giZF2hIZJ-k"
      },
      "source": [
        "import os\n",
        "\n",
        "\t\n",
        "# create directories\n",
        "dataset_home = '/content/drive/MyDrive/data scienec work/dogs-vs-cats/train/'\n",
        "subdirs = ['new_train/', 'new_test/']\n",
        "for subdir in subdirs:\n",
        "\t# create label subdirectories\n",
        "\tlabeldirs = ['dogs/', 'cats/']\n",
        "\tfor labldir in labeldirs:\n",
        "\t\tnewdir = dataset_home + subdir + labldir\n",
        "\t\tos.makedirs(newdir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBBMGcaucHh7"
      },
      "source": [
        "Adding our testing data to newly created directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mJ-BXiKcBrP"
      },
      "source": [
        "from os import makedirs\n",
        "from os import listdir\n",
        "from shutil import copyfile\n",
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "seed(1)\n",
        "# define ratio of pictures to use for validation\n",
        "val_ratio = 0.25\n",
        "# copy training dataset images into subdirectories\n",
        "src_directory = '/content/drive/MyDrive/data scienec work/dogs-vs-cats/train/train'\n",
        "for file in os.listdir(src_directory):\n",
        "\tsrc = src_directory + '/' + file\n",
        "\tdst_dir = '/content/drive/MyDrive/data scienec work/dogs-vs-cats/train/new_train/'\n",
        "\tif random() < val_ratio:\n",
        "\t\tdst_dir = '/content/drive/MyDrive/data scienec work/dogs-vs-cats/train/new_test/'\n",
        "\tif file.startswith('cat'):\n",
        "\t\tdst = dst_dir + 'cats/'  + file\n",
        "\t\tcopyfile(src, dst)\n",
        "\telif file.startswith('dog'):\n",
        "\t\tdst = dst_dir + 'dogs/'  + file\n",
        "\t\tcopyfile(src, dst)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55SrSepZkvhB"
      },
      "source": [
        "Lets build a cnn model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd6tVUnhktiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a103d76-a313-4308-c179-5c13c1a68075"
      },
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image_dataset_from_directory\n",
        "import tensorflow as tf\n",
        "\n",
        " \n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        " \n",
        "def imgMap(img, label):\n",
        "  return (np.asarray(img), label)\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        " \n",
        "\n",
        "    # define model\n",
        "    model = define_model()\n",
        "    # create data generator\n",
        "    datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "    trainit = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        \n",
        "      '/content/drive/MyDrive/data scienec work/dogs-vs-cats/train/new_train',\n",
        "      labels=\"inferred\",\n",
        "      label_mode='binary',\n",
        "      color_mode=\"rgb\",\n",
        "      batch_size=64,\n",
        "      image_size=(200, 200),\n",
        "      shuffle=True,\n",
        "      interpolation=\"bilinear\",\n",
        "      follow_links=False,)\n",
        "\n",
        "    # prepare iterators\n",
        "    '''train_it = datagen.flow_from_directory('/content/drive/MyDrive/data scienec work/dogs-vs-cats/traincr_train',\n",
        "      class_mode='binary', batch_size=64, target_size=(200, 200))  \n",
        "    train_it = train_it.map(imgMap)  \n",
        "    print(train_it)'''\n",
        "\n",
        "    testit = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        \n",
        "      '/content/drive/MyDrive/data scienec work/dogs-vs-cats/train/new_test',\n",
        "      labels=\"inferred\",\n",
        "      label_mode='binary',\n",
        "      color_mode=\"rgb\",\n",
        "      batch_size=64,\n",
        "      image_size=(200, 200),\n",
        "      shuffle=True,\n",
        "      interpolation=\"bilinear\",\n",
        "      follow_links=False,)\n",
        "\n",
        "    \n",
        "    '''test_it = datagen.flow_from_directory('/content/drive/MyDrive/data scienec work/dogs-vs-cats/traincr_test',\n",
        "      class_mode='binary', batch_size=64, target_size=(200, 200))'''\n",
        "    print(testit)\n",
        "    \n",
        "    print(testit)\n",
        "    print(trainit)\n",
        "    # fit model\n",
        "    #history = model.fit_generator(train_it, steps_per_epoch=len(train_it), epochs=20, verbose=0)\n",
        "    history = model.fit(trainit, epochs=10, validation_data=testit, verbose = 1)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate_generator(testit, steps=len(testit), verbose=1)\n",
        "    print('> %.3f' % (acc * 100.0))\n",
        "    # learning curves\n",
        "    summarize_diagnostics(history)\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 18809 files belonging to 2 classes.\n",
            "Found 6351 files belonging to 2 classes.\n",
            "<BatchDataset shapes: ((None, 200, 200, 3), (None, 1)), types: (tf.float32, tf.float32)>\n",
            "<BatchDataset shapes: ((None, 200, 200, 3), (None, 1)), types: (tf.float32, tf.float32)>\n",
            "<BatchDataset shapes: ((None, 200, 200, 3), (None, 1)), types: (tf.float32, tf.float32)>\n",
            "Epoch 1/10\n",
            "294/294 [==============================] - 4564s 15s/step - loss: 5384.8256 - accuracy: 0.4937 - val_loss: 0.6932 - val_accuracy: 0.5100\n",
            "Epoch 2/10\n",
            "294/294 [==============================] - 631s 2s/step - loss: 0.6932 - accuracy: 0.5043 - val_loss: 0.6933 - val_accuracy: 0.4919\n",
            "Epoch 3/10\n",
            "294/294 [==============================] - 625s 2s/step - loss: 0.6931 - accuracy: 0.4967 - val_loss: 0.6933 - val_accuracy: 0.4916\n",
            "Epoch 4/10\n",
            "294/294 [==============================] - 619s 2s/step - loss: 0.6930 - accuracy: 0.4972 - val_loss: 0.6933 - val_accuracy: 0.4917\n",
            "Epoch 5/10\n",
            "294/294 [==============================] - 624s 2s/step - loss: 0.6934 - accuracy: 0.5004 - val_loss: 0.6932 - val_accuracy: 0.5075\n",
            "Epoch 6/10\n",
            "294/294 [==============================] - 624s 2s/step - loss: 0.6930 - accuracy: 0.5052 - val_loss: 0.6932 - val_accuracy: 0.5070\n",
            "Epoch 7/10\n",
            "294/294 [==============================] - 618s 2s/step - loss: 0.6929 - accuracy: 0.5060 - val_loss: 0.6933 - val_accuracy: 0.4920\n",
            "Epoch 8/10\n",
            "294/294 [==============================] - 603s 2s/step - loss: 0.6930 - accuracy: 0.4981 - val_loss: 0.6933 - val_accuracy: 0.4924\n",
            "Epoch 9/10\n",
            "294/294 [==============================] - 596s 2s/step - loss: 0.6929 - accuracy: 0.4966 - val_loss: 0.6933 - val_accuracy: 0.4924\n",
            "Epoch 10/10\n",
            "294/294 [==============================] - 612s 2s/step - loss: 0.6930 - accuracy: 0.5037 - val_loss: 0.6931 - val_accuracy: 0.5070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 72s 708ms/step - loss: 0.6931 - accuracy: 0.5070\n",
            "> 50.701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lbPeqFwxw8W"
      },
      "source": [
        "We can see how previous model performed\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obvegEuvv9yC"
      },
      "source": [
        "# Lets develope two block vgg model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-Fnlen1wFkg",
        "outputId": "653b8f36-60c3-4ef9-8c29-8294e751e679"
      },
      "source": [
        "\n",
        "\t\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "run_test_harness()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 18809 files belonging to 2 classes.\n",
            "Found 6351 files belonging to 2 classes.\n",
            "<BatchDataset shapes: ((None, 200, 200, 3), (None, 1)), types: (tf.float32, tf.float32)>\n",
            "<BatchDataset shapes: ((None, 200, 200, 3), (None, 1)), types: (tf.float32, tf.float32)>\n",
            "<BatchDataset shapes: ((None, 200, 200, 3), (None, 1)), types: (tf.float32, tf.float32)>\n",
            "Epoch 1/10\n",
            "294/294 [==============================] - 1159s 4s/step - loss: 181395564975523.1562 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
            "Epoch 2/10\n",
            "294/294 [==============================] - 1113s 4s/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
            "Epoch 3/10\n",
            "294/294 [==============================] - 1118s 4s/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
            "Epoch 4/10\n",
            "294/294 [==============================] - 1124s 4s/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
            "Epoch 5/10\n",
            "294/294 [==============================] - 1115s 4s/step - loss: 0.6932 - accuracy: 0.4922 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
            "Epoch 6/10\n",
            "294/294 [==============================] - 1098s 4s/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
            "Epoch 7/10\n",
            "294/294 [==============================] - 1094s 4s/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
            "Epoch 8/10\n",
            "294/294 [==============================] - 1097s 4s/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
            "Epoch 9/10\n",
            "294/294 [==============================] - 1106s 4s/step - loss: 0.6932 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
            "Epoch 10/10\n",
            "294/294 [==============================] - 1154s 4s/step - loss: 0.6932 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 125s 1s/step - loss: 0.6931 - accuracy: 0.5075\n",
            "> 50.748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKlrrnZqyScZ"
      },
      "source": [
        "# creating my own data set\n",
        "\n",
        "# just for learning the cnn model\n",
        "\n",
        "\n",
        "import os \n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6MO0ALhzM1L",
        "outputId": "dbe18c6a-dd8f-4680-c216-dde277f30fd2"
      },
      "source": [
        "(xtrain, ytrain), (xtest, ytest)= cifar10.load_data()\n",
        "print(xtrain.shape)\n",
        "print(xtest.shape)\n",
        "print(ytrain.shape)\n",
        "print(ytest.shape)\n",
        "print(type(xtrain))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 1)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx3TckEwzwQS"
      },
      "source": [
        "# to avoid unnecessary computesion we should convert into float32\n",
        "\n",
        "xtrain= xtrain.astype('float32')/255.0\n",
        "xtest= xtest.astype('float32')/255.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "id": "ausfO4cL0uDW",
        "outputId": "acdcd0c3-8522-4c23-aebe-8a32dc914b35"
      },
      "source": [
        "model= keras.Sequential(\n",
        "    [\n",
        "     keras.Input(shape=(32,32,3)),\n",
        "     layers.Conv2D(32,3,padding ='valid', activation='relu'),\n",
        "     layers.MaxPooling2D(pool_size=(2,2)),\n",
        "     layers.Conv2D(64,3,activation='relu'),\n",
        "     layers.Conv2D( 128, 3, activation='relu'),\n",
        "     layers.Flatten(),\n",
        "     layers.Dense(64, activation='relu'),\n",
        "     layers.Dense(10),\n",
        "\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(\n",
        "    loss= keras.losses.SparseCategoricalCrossentropy( from_logits=True),\n",
        "    optimizer = keras.optimizers.Adam(lr= 3e-4),\n",
        "    metrics = ['accuracy'],\n",
        ")\n",
        "\n",
        "model.fit(xtrain, ytrain, batch_size=64, epochs=5, verbose =1 )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_23 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 11, 11, 128)       73856     \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 15488)             0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                991296    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 1,085,194\n",
            "Trainable params: 1,085,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 117s 149ms/step - loss: 4.3435 - accuracy: 0.2452\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 116s 148ms/step - loss: 1.3009 - accuracy: 0.5344\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 115s 147ms/step - loss: 1.0669 - accuracy: 0.6247\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 114s 146ms/step - loss: 0.8680 - accuracy: 0.6968\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 113s 145ms/step - loss: 0.6797 - accuracy: 0.7641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ce3472e42bc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meveluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'eveluate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8qa1ZMs-_YJ",
        "outputId": "42246b05-8817-4a18-8c54-bc9c96048160"
      },
      "source": [
        "model.evaluate(xtest, ytest, batch_size = 64, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 6s 38ms/step - loss: 1.1278 - accuracy: 0.6314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1277672052383423, 0.6313999891281128]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F041fZR3yL_O"
      },
      "source": [
        "# Three block vgg model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwlW3ubuyPvb"
      },
      "source": [
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "run_test_harness()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urgaVMPC1isp"
      },
      "source": [
        "Let improve model accuracy by dropping out regularization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-gy3KHt1u33"
      },
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qApLdRQO2XS7"
      },
      "source": [
        "Lets increase accuracy by image data agumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZfIvpLj2cnE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "CBzcgJBku1Zv",
        "outputId": "a12e1fb0-7fb8-4d87-8c4a-2f12c39e5d56"
      },
      "source": [
        "# Lets plot the error rae based on iteration\n",
        "\n",
        "summarize_diagnostics(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f05e2cce68f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Lets plot the error rae based on iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msummarize_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsu3FeZL2iV_",
        "outputId": "87a66aaa-2a92-411f-db40-9359baf4fcf8"
      },
      "source": [
        "# Since we are getting following error Now I need to check whether all the file in correct order \n",
        "\n",
        "# Generating a data frame which will have file name and level\n",
        "cat_folder = '/content/drive/MyDrive/data scienec work/dogs-vs-cats/traincr_train/cats'\n",
        "dog_folder = '/content/drive/MyDrive/data scienec work/dogs-vs-cats/traincr_train/dogs'\n",
        "\n",
        "filenames=os.listdir(cat_folder)\n",
        "\n",
        "\n",
        "categories=[]\n",
        "for f_name in filenames:\n",
        "    category=f_name.split('.')[0]\n",
        "    if category=='dog':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "\n",
        "\n",
        "\n",
        "cat_df=pd.DataFrame({\n",
        "    'filename':filenames,\n",
        "    'category':categories\n",
        "})\n",
        "\n",
        "\n",
        "filenames=os.listdir(dog_folder)\n",
        "categories=[]\n",
        "for f_name in filenames:\n",
        "    category=f_name.split('.')[0]\n",
        "    if category=='dog':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "\n",
        "\n",
        "\n",
        "dog_df=pd.DataFrame({\n",
        "    'filename':filenames,\n",
        "    'category':categories\n",
        "})\n",
        "\n",
        "print(cat_df.shape, cat_df.columns)\n",
        "print(dog_df.shape, dog_df.columns)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9383, 2) Index(['filename', 'category'], dtype='object')\n",
            "(9427, 2) Index(['filename', 'category'], dtype='object')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fut4erHs9tJd",
        "outputId": "5fd939ec-733a-4b38-e56b-7516977fd358"
      },
      "source": [
        "print(cat_df['filename'][830:870])\n",
        "print(dog_df['filename'][830:870])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "830    cat.10975.jpg\n",
            "831    cat.10976.jpg\n",
            "832    cat.10986.jpg\n",
            "833    cat.10978.jpg\n",
            "834    cat.10981.jpg\n",
            "835     cat.1099.jpg\n",
            "836    cat.10997.jpg\n",
            "837    cat.10987.jpg\n",
            "838    cat.10991.jpg\n",
            "839    cat.10998.jpg\n",
            "840    cat.11000.jpg\n",
            "841    cat.10984.jpg\n",
            "842    cat.10979.jpg\n",
            "843     cat.1100.jpg\n",
            "844    cat.10980.jpg\n",
            "845    cat.10985.jpg\n",
            "846    cat.10995.jpg\n",
            "847    cat.10994.jpg\n",
            "848    cat.10993.jpg\n",
            "849    cat.10988.jpg\n",
            "850    cat.10983.jpg\n",
            "851     cat.1098.jpg\n",
            "852    cat.10977.jpg\n",
            "853      cat.110.jpg\n",
            "854    cat.10974.jpg\n",
            "855     cat.1102.jpg\n",
            "856    cat.11029.jpg\n",
            "857    cat.11012.jpg\n",
            "858    cat.11013.jpg\n",
            "859     cat.1101.jpg\n",
            "860    cat.11023.jpg\n",
            "861    cat.11011.jpg\n",
            "862    cat.11009.jpg\n",
            "863    cat.11005.jpg\n",
            "864    cat.11004.jpg\n",
            "865    cat.11016.jpg\n",
            "866    cat.11003.jpg\n",
            "867     cat.1103.jpg\n",
            "868    cat.11007.jpg\n",
            "869    cat.11002.jpg\n",
            "Name: filename, dtype: object\n",
            "830    dog.10372.jpg\n",
            "831    dog.10392.jpg\n",
            "832    dog.10390.jpg\n",
            "833    dog.10374.jpg\n",
            "834    dog.10381.jpg\n",
            "835    dog.10382.jpg\n",
            "836    dog.10380.jpg\n",
            "837     dog.1038.jpg\n",
            "838    dog.10391.jpg\n",
            "839    dog.10369.jpg\n",
            "840    dog.10393.jpg\n",
            "841    dog.10371.jpg\n",
            "842    dog.10383.jpg\n",
            "843    dog.10376.jpg\n",
            "844     dog.1039.jpg\n",
            "845    dog.10370.jpg\n",
            "846    dog.10377.jpg\n",
            "847     dog.1040.jpg\n",
            "848    dog.10410.jpg\n",
            "849    dog.10409.jpg\n",
            "850    dog.10412.jpg\n",
            "851    dog.10413.jpg\n",
            "852    dog.10399.jpg\n",
            "853    dog.10403.jpg\n",
            "854    dog.10398.jpg\n",
            "855     dog.1041.jpg\n",
            "856    dog.10414.jpg\n",
            "857    dog.10406.jpg\n",
            "858    dog.10394.jpg\n",
            "859    dog.10400.jpg\n",
            "860    dog.10397.jpg\n",
            "861    dog.10408.jpg\n",
            "862      dog.104.jpg\n",
            "863    dog.10402.jpg\n",
            "864    dog.10395.jpg\n",
            "865    dog.10396.jpg\n",
            "866    dog.10401.jpg\n",
            "867    dog.10411.jpg\n",
            "868    dog.10416.jpg\n",
            "869    dog.10426.jpg\n",
            "Name: filename, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7poYvzOl3aRZ"
      },
      "source": [
        "Now we have created a csv file, so lets check wheter all file in correct formate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SvV0nWl3imM",
        "outputId": "aafa5015-1d22-4c25-d724-e182f6578f44"
      },
      "source": [
        "for i in ['filename', 'category']:\n",
        "\n",
        "  print(cat_df.pivot_table(columns=i, aggfunc=np.sum))\n",
        "  print(dog_df.pivot_table(columns=i,aggfunc=np.sum))\n",
        "\n",
        "\n",
        "k=0\n",
        "for i in list(cat_df['filename']):\n",
        "  if 'jpg' in i.split('.'):\n",
        "    k=k+1\n",
        "\n",
        "print(k)\n",
        "k=0\n",
        "for i in list(dog_df['filename']):\n",
        "\n",
        "  if 'jpg' in i.split('.'):\n",
        "    k=k+1\n",
        "print(k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "filename  cat.0.jpg  cat.1.jpg  ...  cat.9998.jpg  cat.9999.jpg\n",
            "category          0          0  ...             0             0\n",
            "\n",
            "[1 rows x 9383 columns]\n",
            "filename  dog.0.jpg  dog.1.jpg  ...  dog.9997.jpg  dog.9999.jpg\n",
            "category          1          1  ...             1             1\n",
            "\n",
            "[1 rows x 9427 columns]\n",
            "category                                                  0\n",
            "filename  cat.11781.jpgcat.11783.jpgcat.11767.jpgcat.117...\n",
            "category                                                  1\n",
            "filename  dog.10849.jpgdog.10845.jpgdog.10888.jpgdog.108...\n",
            "9383\n",
            "9427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKKun77S6GQS",
        "outputId": "76bf32bf-d87f-4804-f283-1483ad203620"
      },
      "source": [
        "# We need to check same thing for test_df\n",
        "\n",
        "cat_folder = '/content/drive/MyDrive/data scienec work/dogs-vs-cats/traincr_test/cats'\n",
        "dog_folder = '/content/drive/MyDrive/data scienec work/dogs-vs-cats/traincr_test/dogs'\n",
        "\n",
        "filenames=os.listdir(cat_folder)\n",
        "\n",
        "\n",
        "categories=[]\n",
        "for f_name in filenames:\n",
        "    category=f_name.split('.')[0]\n",
        "    if category=='dog':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "\n",
        "\n",
        "\n",
        "cat_df=pd.DataFrame({\n",
        "    'filename':filenames,\n",
        "    'category':categories\n",
        "})\n",
        "\n",
        "\n",
        "filenames=os.listdir(dog_folder)\n",
        "categories=[]\n",
        "for f_name in filenames:\n",
        "    category=f_name.split('.')[0]\n",
        "    if category=='dog':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "\n",
        "\n",
        "\n",
        "dog_df=pd.DataFrame({\n",
        "    'filename':filenames,\n",
        "    'category':categories\n",
        "})\n",
        "\n",
        "print(cat_df.shape, cat_df.columns)\n",
        "print(dog_df.shape, dog_df.columns)\n",
        "print()\n",
        "\n",
        "for i in ['filename', 'category']:\n",
        "\n",
        "  print(pd.pivot_table(cat_df, columns=i, aggfunc=np.sum))\n",
        "  print(pd.pivot_table(dog_df, columns=i,aggfunc=np.sum))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3127, 2) Index(['filename', 'category'], dtype='object')\n",
            "(3223, 2) Index(['filename', 'category'], dtype='object')\n",
            "\n",
            "filename  cat.10.jpg  cat.10004.jpg  ...  cat.9995.jpg  cat.9996.jpg\n",
            "category           0              0  ...             0             0\n",
            "\n",
            "[1 rows x 3127 columns]\n",
            "filename  dog.100.jpg  dog.10004.jpg  ...  dog.9995.jpg  dog.9998.jpg\n",
            "category            1              1  ...             1             1\n",
            "\n",
            "[1 rows x 3223 columns]\n",
            "category                                                  0\n",
            "filename  cat.1784.jpgcat.1759.jpgcat.1779.jpgcat.1758.j...\n",
            "category                                                  1\n",
            "filename  dog.2645.jpgdog.2654.jpgdog.2652.jpgdog.2663.j...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPWQWs7s63h9",
        "outputId": "7408ea45-2dec-4fb3-ecbd-4e4cda2ca050"
      },
      "source": [
        "k=0\n",
        "for i in list(cat_df['filename']):\n",
        "  if 'jpg' in i.split('.'):\n",
        "    k=k+1\n",
        "\n",
        "print(k)\n",
        "k=0\n",
        "for i in list(dog_df['filename']):\n",
        "\n",
        "  if 'jpg' in i.split('.'):\n",
        "    k=k+1\n",
        "print(k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3127\n",
            "3223\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}